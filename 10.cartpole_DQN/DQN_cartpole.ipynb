{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN(Deep Q-Network)\n",
    "\n",
    "- DQN이전 CNN이 아닌 AutoEncoder를 이용한 사례가 있음\n",
    "    - 논문 : Deep auto-encoder neural networks in reinforcement learning - Sascha Lange and Martin Riedmiller(https://ieeexplore.ieee.org/document/5596468)\n",
    "    - AutoEncoder를 일종의 dimenstion reduction으로 사용함\n",
    "    - 학습된 latent variable(900 -> 2)으로 policy을 학습\n",
    "    \n",
    "### CNN\n",
    "- 화면으로부터 direct로 학습\n",
    "\n",
    "### Experience replay\n",
    "- Sample들의 상관관계를 없애는 방법\n",
    "- 일정한 크기를 갖는 mem(FIFO)\n",
    "\n",
    "### Online Learning with Stochastic gradient descent\n",
    "- 고정된 policy를 사용하지 않음\n",
    "- 큐함수에 대한 $\\epsilon$-greedy\n",
    "- $\\epsilon$-greedy policy로 탐험 reply mem에서 추출한 mini-batch로 큐함수를 업데이트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습과정\n",
    "### 1. Exploration\n",
    "- policy는 큐함수에 대한 $\\epsilon$-greedy\n",
    "- $\\epsilon$은 time step에 따라 decay, 1에서 시작 -> 0.1까지 decay, 0.1 유지\n",
    "\n",
    "### 2. Sample 저장\n",
    "- 에이전트는 $\\epsilon$-greedy policy에 따라서 [s, a, r, s']을 생성하고 reply mem에 append\n",
    "\n",
    "### 3. random sampling으로 학습\n",
    "- 미니배치 32\n",
    "- 샘플로부터 target값과 prediction의 값을 구함\n",
    "    - MSE : $(target - prediction)^2$\n",
    "    - Target : $reward + \\gamma \\ max_{a'} q_{\\theta} (s', a)$\n",
    "    - Prediction : $q_{\\theta}(s, a)$\n",
    "- MSE error에 대한 gradient backpropagation설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN 모형 설계 및 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T09:28:27.845106Z",
     "start_time": "2018-05-07T09:28:27.208818Z"
    }
   },
   "source": [
    "### 1. Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T10:28:36.282081Z",
     "start_time": "2018-05-11T10:28:33.347151Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-07T09:28:27.845106Z",
     "start_time": "2018-05-07T09:28:27.208818Z"
    }
   },
   "source": [
    "### 2. Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T10:28:36.698645Z",
     "start_time": "2018-05-11T10:28:36.325726Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "np.random.seed(123)\n",
    "EPISODES = 300\n",
    "global_steps = 0\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.render = False\n",
    "        self.load_model = False\n",
    "        \n",
    "        # 상태와 행동의 크기를 정의\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        \n",
    "        # DQN 하이퍼파라미터\n",
    "        self.discount_factor = 0.99\n",
    "        self.learning_rate = 0.001\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_decay = 0.999\n",
    "        self.epsilon_min = 0.01\n",
    "        self.batch_size = 64\n",
    "        self.train_start = 1000\n",
    "        \n",
    "        # 리플라이 메모리\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        \n",
    "        # 모델과 타깃 모델 생성dones\n",
    "        self.model = self.build_model()\n",
    "        self.target_model = self.build_model()\n",
    "        \n",
    "        # 타겟 모델 초기화\n",
    "        self.update_target_model()\n",
    "        \n",
    "        if self.load_model:\n",
    "            self.model.load_model.load_weights('./save_model/cartpole_dqn_trained.h5')\n",
    "            \n",
    "            \n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim=self.state_size, activation='relu',\n",
    "                       kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(24, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(self.action_size, activation='linear', kernel_initializer='he_uniform'))\n",
    "        model.summary()\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "    \n",
    "    \n",
    "    # 타깃 모델을 모델의 가중치로 업데이트\n",
    "    def update_target_model(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "    \n",
    "    \n",
    "    # 입실론 탐욕 정책으로 행동을 선택\n",
    "    def get_action(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        else:\n",
    "            q_value = self.model.predict(state)\n",
    "            return np.argmax(q_value[0])\n",
    "        \n",
    "    # 리플라이 메모리 설정\n",
    "    def append_sample(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        \n",
    "        \n",
    "    # 리플레이 메모리에서 무작위로 추출한 배치로 모델을 학습함\n",
    "    def train_model(self):\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "        # 메로리에서 배치 크기만큼 무작위로 샘플 추출\n",
    "        mini_batch = random.sample(self.memory, self.batch_size)\n",
    "        \n",
    "        states = np.zeros((self.batch_size, self.state_size))\n",
    "        next_states = np.zeros((self.batch_size, self.state_size))\n",
    "        actions, rewards, dones = [], [], []\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            states[i] = mini_batch[i][0]\n",
    "            actions.append(mini_batch[i][1])\n",
    "            rewards.append(mini_batch[i][2])\n",
    "            next_states[i] = mini_batch[i][3]\n",
    "            dones.append(mini_batch[i][4])\n",
    "        \n",
    "        # 현재 상태에 대한 모델의 큐함수\n",
    "        # 다음 상태에 대한 타깃 모델의 큐함수\n",
    "        target = self.model.predict(states)\n",
    "        target_val = self.target_model.predict(next_states)\n",
    "        \n",
    "        # 벨만 최적 방정식을 이용한 업데이트 타깃\n",
    "        for i in range(self.batch_size):\n",
    "            if dones[i]:\n",
    "                target[i][actions[i]] = rewards[i]\n",
    "            else:\n",
    "                target[i][actions[i]] = rewards[i] + self.discount_factor * (\n",
    "                    np.amax(target_val[i]))\n",
    "                \n",
    "        self.model.fit(states, target, batch_size=self.batch_size, epochs=1, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 에이전트 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T10:28:36.999679Z",
     "start_time": "2018-05-11T10:28:36.741779Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-11 19:28:36,780] Making new env: CartPole-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 24)                120       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 50        \n",
      "=================================================================\n",
      "Total params: 770\n",
      "Trainable params: 770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 24)                120       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 50        \n",
      "=================================================================\n",
      "Total params: 770\n",
      "Trainable params: 770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "graph_path = os.path.join(os.getcwd(), 'save_graph')\n",
    "model_path = os.path.join(os.getcwd(), 'save_model')\n",
    "\n",
    "if not os.path.isdir(graph_path):\n",
    "    os.mkdir(graph_path)\n",
    "if not os.path.isdir(model_path):\n",
    "    os.mkdir(model_path)\n",
    "\n",
    "env  = gym.make('CartPole-v1')\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n\n",
    "\n",
    "# DQN 에이전트 생성\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "scores, episodes = [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train 시작\n",
    "- Cartpole의 한 episode는 500개의 step\n",
    "- 에이전트는 환경을 통해 한 번 step이 진행되면 1의 reward를 받음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-11T10:41:48.303710Z",
     "start_time": "2018-05-11T10:28:37.061502Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-05-11 19:28:37,307] Making new env: CartPole-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 24)                120       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 50        \n",
      "=================================================================\n",
      "Total params: 770\n",
      "Trainable params: 770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 24)                120       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 50        \n",
      "=================================================================\n",
      "Total params: 770\n",
      "Trainable params: 770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "episode: 0   score: 16.0   memory length: 17   epsilon: 1.0 global steps:  17\n",
      "episode: 1   score: 38.0   memory length: 56   epsilon: 1.0 global steps:  56\n",
      "episode: 2   score: 19.0   memory length: 76   epsilon: 1.0 global steps:  76\n",
      "episode: 3   score: 23.0   memory length: 100   epsilon: 1.0 global steps:  100\n",
      "episode: 4   score: 50.0   memory length: 151   epsilon: 1.0 global steps:  151\n",
      "episode: 5   score: 19.0   memory length: 171   epsilon: 1.0 global steps:  171\n",
      "episode: 6   score: 10.0   memory length: 182   epsilon: 1.0 global steps:  182\n",
      "episode: 7   score: 23.0   memory length: 206   epsilon: 1.0 global steps:  206\n",
      "episode: 8   score: 23.0   memory length: 230   epsilon: 1.0 global steps:  230\n",
      "episode: 9   score: 20.0   memory length: 251   epsilon: 1.0 global steps:  251\n",
      "episode: 10   score: 14.0   memory length: 266   epsilon: 1.0 global steps:  266\n",
      "episode: 11   score: 8.0   memory length: 275   epsilon: 1.0 global steps:  275\n",
      "episode: 12   score: 31.0   memory length: 307   epsilon: 1.0 global steps:  307\n",
      "episode: 13   score: 19.0   memory length: 327   epsilon: 1.0 global steps:  327\n",
      "episode: 14   score: 8.0   memory length: 336   epsilon: 1.0 global steps:  336\n",
      "episode: 15   score: 11.0   memory length: 348   epsilon: 1.0 global steps:  348\n",
      "episode: 16   score: 19.0   memory length: 368   epsilon: 1.0 global steps:  368\n",
      "episode: 17   score: 12.0   memory length: 381   epsilon: 1.0 global steps:  381\n",
      "episode: 18   score: 19.0   memory length: 401   epsilon: 1.0 global steps:  401\n",
      "episode: 19   score: 20.0   memory length: 422   epsilon: 1.0 global steps:  422\n",
      "episode: 20   score: 10.0   memory length: 433   epsilon: 1.0 global steps:  433\n",
      "episode: 21   score: 12.0   memory length: 446   epsilon: 1.0 global steps:  446\n",
      "episode: 22   score: 17.0   memory length: 464   epsilon: 1.0 global steps:  464\n",
      "episode: 23   score: 26.0   memory length: 491   epsilon: 1.0 global steps:  491\n",
      "episode: 24   score: 11.0   memory length: 503   epsilon: 1.0 global steps:  503\n",
      "episode: 25   score: 10.0   memory length: 514   epsilon: 1.0 global steps:  514\n",
      "episode: 26   score: 21.0   memory length: 536   epsilon: 1.0 global steps:  536\n",
      "episode: 27   score: 38.0   memory length: 575   epsilon: 1.0 global steps:  575\n",
      "episode: 28   score: 10.0   memory length: 586   epsilon: 1.0 global steps:  586\n",
      "episode: 29   score: 19.0   memory length: 606   epsilon: 1.0 global steps:  606\n",
      "episode: 30   score: 17.0   memory length: 624   epsilon: 1.0 global steps:  624\n",
      "episode: 31   score: 24.0   memory length: 649   epsilon: 1.0 global steps:  649\n",
      "episode: 32   score: 32.0   memory length: 682   epsilon: 1.0 global steps:  682\n",
      "episode: 33   score: 11.0   memory length: 694   epsilon: 1.0 global steps:  694\n",
      "episode: 34   score: 29.0   memory length: 724   epsilon: 1.0 global steps:  724\n",
      "episode: 35   score: 17.0   memory length: 742   epsilon: 1.0 global steps:  742\n",
      "episode: 36   score: 11.0   memory length: 754   epsilon: 1.0 global steps:  754\n",
      "episode: 37   score: 29.0   memory length: 784   epsilon: 1.0 global steps:  784\n",
      "episode: 38   score: 30.0   memory length: 815   epsilon: 1.0 global steps:  815\n",
      "episode: 39   score: 20.0   memory length: 836   epsilon: 1.0 global steps:  836\n",
      "episode: 40   score: 70.0   memory length: 907   epsilon: 1.0 global steps:  907\n",
      "episode: 41   score: 15.0   memory length: 923   epsilon: 1.0 global steps:  923\n",
      "episode: 42   score: 15.0   memory length: 939   epsilon: 1.0 global steps:  939\n",
      "episode: 43   score: 39.0   memory length: 979   epsilon: 1.0 global steps:  979\n",
      "episode: 44   score: 64.0   memory length: 1044   epsilon: 0.9559759577813409 global steps:  1044\n",
      "episode: 45   score: 30.0   memory length: 1075   epsilon: 0.9267809647166116 global steps:  1075\n",
      "episode: 46   score: 49.0   memory length: 1125   epsilon: 0.8815592697443159 global steps:  1125\n",
      "episode: 47   score: 18.0   memory length: 1144   epsilon: 0.8649595394300645 global steps:  1144\n",
      "episode: 48   score: 17.0   memory length: 1162   epsilon: 0.8495219033622532 global steps:  1162\n",
      "episode: 49   score: 10.0   memory length: 1173   epsilon: 0.8402237462387894 global steps:  1173\n",
      "episode: 50   score: 80.0   memory length: 1254   epsilon: 0.7748176364970056 global steps:  1254\n",
      "episode: 51   score: 20.0   memory length: 1275   epsilon: 0.7587081519483351 global steps:  1275\n",
      "episode: 52   score: 60.0   memory length: 1336   epsilon: 0.7137884761549381 global steps:  1336\n",
      "episode: 53   score: 42.0   memory length: 1379   epsilon: 0.6837314012165328 global steps:  1379\n",
      "episode: 54   score: 73.0   memory length: 1453   epsilon: 0.6349384896673435 global steps:  1453\n",
      "episode: 55   score: 15.0   memory length: 1469   epsilon: 0.6248553120386914 global steps:  1469\n",
      "episode: 56   score: 20.0   memory length: 1490   epsilon: 0.6118637427709198 global steps:  1490\n",
      "episode: 57   score: 26.0   memory length: 1517   epsilon: 0.5955564068773637 global steps:  1517\n",
      "episode: 58   score: 74.0   memory length: 1592   epsilon: 0.5525028441531146 global steps:  1592\n",
      "episode: 59   score: 19.0   memory length: 1612   epsilon: 0.5415571356255309 global steps:  1612\n",
      "episode: 60   score: 95.0   memory length: 1708   epsilon: 0.4919615398850291 global steps:  1708\n",
      "episode: 61   score: 65.0   memory length: 1774   epsilon: 0.46052517380982005 global steps:  1774\n",
      "episode: 62   score: 67.0   memory length: 1842   epsilon: 0.4302358289512637 global steps:  1842\n",
      "episode: 63   score: 110.0   memory length: 1953   epsilon: 0.3850133314162377 global steps:  1953\n",
      "episode: 64   score: 55.0   memory length: 2000   epsilon: 0.36403497277104113 global steps:  2009\n",
      "episode: 65   score: 99.0   memory length: 2000   epsilon: 0.3293759846379912 global steps:  2109\n",
      "episode: 66   score: 108.0   memory length: 2000   epsilon: 0.2953453567182228 global steps:  2218\n",
      "episode: 67   score: 218.0   memory length: 2000   epsilon: 0.23723134382036148 global steps:  2437\n",
      "episode: 68   score: 107.0   memory length: 2000   epsilon: 0.21293389453887626 global steps:  2545\n",
      "episode: 69   score: 199.0   memory length: 2000   epsilon: 0.1743180835205783 global steps:  2745\n",
      "episode: 70   score: 500.0   memory length: 2000   epsilon: 0.10570281555543207 global steps:  3245\n",
      "episode: 71   score: 167.0   memory length: 2000   epsilon: 0.08934876984714372 global steps:  3413\n",
      "episode: 72   score: 500.0   memory length: 2000   epsilon: 0.054179212784555925 global steps:  3913\n",
      "episode: 73   score: 425.0   memory length: 2000   epsilon: 0.03537778797291631 global steps:  4339\n",
      "episode: 74   score: 237.0   memory length: 2000   epsilon: 0.02788154736977743 global steps:  4577\n",
      "episode: 75   score: 500.0   memory length: 2000   epsilon: 0.016906783275182764 global steps:  5077\n",
      "episode: 76   score: 330.0   memory length: 2000   epsilon: 0.012140528375631197 global steps:  5408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 77   score: 317.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  5726\n",
      "episode: 78   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  6226\n",
      "episode: 79   score: 326.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  6553\n",
      "episode: 80   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  7053\n",
      "episode: 81   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  7553\n",
      "episode: 82   score: 424.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  7978\n",
      "episode: 83   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  8478\n",
      "episode: 84   score: 314.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  8793\n",
      "episode: 85   score: 469.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  9263\n",
      "episode: 86   score: 432.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  9696\n",
      "episode: 87   score: 256.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  9953\n",
      "episode: 88   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  10453\n",
      "episode: 89   score: 294.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  10748\n",
      "episode: 90   score: 466.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  11215\n",
      "episode: 91   score: 264.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  11480\n",
      "episode: 92   score: 333.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  11814\n",
      "episode: 93   score: 362.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  12177\n",
      "episode: 94   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  12677\n",
      "episode: 95   score: 286.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  12964\n",
      "episode: 96   score: 255.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  13220\n",
      "episode: 97   score: 280.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  13501\n",
      "episode: 98   score: 234.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  13736\n",
      "episode: 99   score: 315.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  14052\n",
      "episode: 100   score: 295.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  14348\n",
      "episode: 101   score: 343.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  14692\n",
      "episode: 102   score: 334.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  15027\n",
      "episode: 103   score: 251.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  15279\n",
      "episode: 104   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  15779\n",
      "episode: 105   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  16279\n",
      "episode: 106   score: 238.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  16518\n",
      "episode: 107   score: 484.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  17003\n",
      "episode: 108   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  17503\n",
      "episode: 109   score: 481.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  17985\n",
      "episode: 110   score: 449.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  18435\n",
      "episode: 111   score: 362.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  18798\n",
      "episode: 112   score: 443.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  19242\n",
      "episode: 113   score: 231.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  19474\n",
      "episode: 114   score: 294.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  19769\n",
      "episode: 115   score: 330.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  20100\n",
      "episode: 116   score: 272.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  20373\n",
      "episode: 117   score: 285.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  20659\n",
      "episode: 118   score: 306.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  20966\n",
      "episode: 119   score: 303.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  21270\n",
      "episode: 120   score: 346.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  21617\n",
      "episode: 121   score: 306.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  21924\n",
      "episode: 122   score: 325.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  22250\n",
      "episode: 123   score: 295.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  22546\n",
      "episode: 124   score: 279.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  22826\n",
      "episode: 125   score: 340.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  23167\n",
      "episode: 126   score: 436.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  23604\n",
      "episode: 127   score: 377.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  23982\n",
      "episode: 128   score: 386.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  24369\n",
      "episode: 129   score: 357.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  24727\n",
      "episode: 130   score: 401.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  25129\n",
      "episode: 131   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  25629\n",
      "episode: 132   score: 298.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  25928\n",
      "episode: 133   score: 284.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  26213\n",
      "episode: 134   score: 317.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  26531\n",
      "episode: 135   score: 275.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  26807\n",
      "episode: 136   score: 347.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  27155\n",
      "episode: 137   score: 342.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  27498\n",
      "episode: 138   score: 360.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  27859\n",
      "episode: 139   score: 361.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  28221\n",
      "episode: 140   score: 319.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  28541\n",
      "episode: 141   score: 325.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  28867\n",
      "episode: 142   score: 350.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  29218\n",
      "episode: 143   score: 337.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  29556\n",
      "episode: 144   score: 363.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  29920\n",
      "episode: 145   score: 365.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  30286\n",
      "episode: 146   score: 375.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  30662\n",
      "episode: 147   score: 337.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  31000\n",
      "episode: 148   score: 354.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  31355\n",
      "episode: 149   score: 361.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  31717\n",
      "episode: 150   score: 363.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  32081\n",
      "episode: 151   score: 349.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  32431\n",
      "episode: 152   score: 346.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  32778\n",
      "episode: 153   score: 370.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  33149\n",
      "episode: 154   score: 390.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  33540\n",
      "episode: 155   score: 412.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  33953\n",
      "episode: 156   score: 378.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  34332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 157   score: 375.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  34708\n",
      "episode: 158   score: 410.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  35119\n",
      "episode: 159   score: 377.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  35497\n",
      "episode: 160   score: 393.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  35891\n",
      "episode: 161   score: 446.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  36338\n",
      "episode: 162   score: 377.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  36716\n",
      "episode: 163   score: 369.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  37086\n",
      "episode: 164   score: 375.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  37462\n",
      "episode: 165   score: 343.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  37806\n",
      "episode: 166   score: 398.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  38205\n",
      "episode: 167   score: 430.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  38636\n",
      "episode: 168   score: 410.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  39047\n",
      "episode: 169   score: 393.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  39441\n",
      "episode: 170   score: 365.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  39807\n",
      "episode: 171   score: 382.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  40190\n",
      "episode: 172   score: 366.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  40557\n",
      "episode: 173   score: 350.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  40908\n",
      "episode: 174   score: 390.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  41299\n",
      "episode: 175   score: 367.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  41667\n",
      "episode: 176   score: 352.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  42020\n",
      "episode: 177   score: 360.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  42381\n",
      "episode: 178   score: 394.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  42776\n",
      "episode: 179   score: 334.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  43111\n",
      "episode: 180   score: 372.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  43484\n",
      "episode: 181   score: 350.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  43835\n",
      "episode: 182   score: 359.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  44195\n",
      "episode: 183   score: 446.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  44642\n",
      "episode: 184   score: 402.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  45045\n",
      "episode: 185   score: 381.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  45427\n",
      "episode: 186   score: 399.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  45827\n",
      "episode: 187   score: 436.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  46264\n",
      "episode: 188   score: 431.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  46696\n",
      "episode: 189   score: 466.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  47163\n",
      "episode: 190   score: 462.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  47626\n",
      "episode: 191   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  48126\n",
      "episode: 192   score: 497.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  48624\n",
      "episode: 193   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  49124\n",
      "episode: 194   score: 440.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  49565\n",
      "episode: 195   score: 425.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  49991\n",
      "episode: 196   score: 425.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  50417\n",
      "episode: 197   score: 10.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  50428\n",
      "episode: 198   score: 74.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  50503\n",
      "episode: 199   score: 173.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  50677\n",
      "episode: 200   score: 34.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  50712\n",
      "episode: 201   score: 48.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  50761\n",
      "episode: 202   score: 54.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  50816\n",
      "episode: 203   score: 59.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  50876\n",
      "episode: 204   score: 68.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  50945\n",
      "episode: 205   score: 77.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  51023\n",
      "episode: 206   score: 68.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  51092\n",
      "episode: 207   score: 68.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  51161\n",
      "episode: 208   score: 60.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  51222\n",
      "episode: 209   score: 74.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  51297\n",
      "episode: 210   score: 75.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  51373\n",
      "episode: 211   score: 121.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  51495\n",
      "episode: 212   score: 124.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  51620\n",
      "episode: 213   score: 140.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  51761\n",
      "episode: 214   score: 127.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  51889\n",
      "episode: 215   score: 140.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  52030\n",
      "episode: 216   score: 140.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  52171\n",
      "episode: 217   score: 129.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  52301\n",
      "episode: 218   score: 122.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  52424\n",
      "episode: 219   score: 143.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  52568\n",
      "episode: 220   score: 147.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  52716\n",
      "episode: 221   score: 132.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  52849\n",
      "episode: 222   score: 137.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  52987\n",
      "episode: 223   score: 145.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  53133\n",
      "episode: 224   score: 165.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  53299\n",
      "episode: 225   score: 145.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  53445\n",
      "episode: 226   score: 191.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  53637\n",
      "episode: 227   score: 175.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  53813\n",
      "episode: 228   score: 160.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  53974\n",
      "episode: 229   score: 187.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  54162\n",
      "episode: 230   score: 228.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  54391\n",
      "episode: 231   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  54891\n",
      "episode: 232   score: 365.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  55257\n",
      "episode: 233   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  55757\n",
      "episode: 234   score: 307.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  56065\n",
      "episode: 235   score: 195.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  56261\n",
      "episode: 236   score: 216.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  56478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 237   score: 198.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  56677\n",
      "episode: 238   score: 205.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  56883\n",
      "episode: 239   score: 226.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  57110\n",
      "episode: 240   score: 219.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  57330\n",
      "episode: 241   score: 212.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  57543\n",
      "episode: 242   score: 272.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  57816\n",
      "episode: 243   score: 293.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  58110\n",
      "episode: 244   score: 465.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  58576\n",
      "episode: 245   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  59076\n",
      "episode: 246   score: 307.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  59384\n",
      "episode: 247   score: 302.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  59687\n",
      "episode: 248   score: 287.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  59975\n",
      "episode: 249   score: 266.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  60242\n",
      "episode: 250   score: 292.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  60535\n",
      "episode: 251   score: 366.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  60902\n",
      "episode: 252   score: 273.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  61176\n",
      "episode: 253   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  61676\n",
      "episode: 254   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  62176\n",
      "episode: 255   score: 418.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  62595\n",
      "episode: 256   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  63095\n",
      "episode: 257   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  63595\n",
      "episode: 258   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  64095\n",
      "episode: 259   score: 472.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  64568\n",
      "episode: 260   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  65068\n",
      "episode: 261   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  65568\n",
      "episode: 262   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  66068\n",
      "episode: 263   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  66568\n",
      "episode: 264   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  67068\n",
      "episode: 265   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  67568\n",
      "episode: 266   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  68068\n",
      "episode: 267   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  68568\n",
      "episode: 268   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  69068\n",
      "episode: 269   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  69568\n",
      "episode: 270   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  70068\n",
      "episode: 271   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  70568\n",
      "episode: 272   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  71068\n",
      "episode: 273   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  71568\n",
      "episode: 274   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  72068\n",
      "episode: 275   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  72568\n",
      "episode: 276   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  73068\n",
      "episode: 277   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  73568\n",
      "episode: 278   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  74068\n",
      "episode: 279   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  74568\n",
      "episode: 280   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  75068\n",
      "episode: 281   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  75568\n",
      "episode: 282   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  76068\n",
      "episode: 283   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  76568\n",
      "episode: 284   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  77068\n",
      "episode: 285   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  77568\n",
      "episode: 286   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  78068\n",
      "episode: 287   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  78568\n",
      "episode: 288   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  79068\n",
      "episode: 289   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  79568\n",
      "episode: 290   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  80068\n",
      "episode: 291   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  80568\n",
      "episode: 292   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  81068\n",
      "episode: 293   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  81568\n",
      "episode: 294   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  82068\n",
      "episode: 295   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  82568\n",
      "episode: 296   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  83068\n",
      "episode: 297   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  83568\n",
      "episode: 298   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  84068\n",
      "episode: 299   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896 global steps:  84568\n",
      "0:13:10.300175\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f24bdf63c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    start = datetime.datetime.now()\n",
    "    \n",
    "    graph_path = os.path.join(os.getcwd(), 'save_graph')\n",
    "    model_path = os.path.join(os.getcwd(), 'save_model')\n",
    "\n",
    "    if not os.path.isdir(graph_path):\n",
    "        os.mkdir(graph_path)\n",
    "    if not os.path.isdir(model_path):\n",
    "        os.mkdir(model_path)\n",
    "\n",
    "    # CartPole-v1 환경, 최대 타임스텝 수가 500\n",
    "    env = gym.make('CartPole-v1')\n",
    "    state_size = env.observation_space.shape[0]\n",
    "    action_size = env.action_space.n\n",
    "\n",
    "    # DQN 에이전트 생성\n",
    "    agent = DQNAgent(state_size, action_size)\n",
    "\n",
    "    scores, episodes = [], []\n",
    "\n",
    "    \n",
    "    # \n",
    "    for e in range(EPISODES):\n",
    "        done = False\n",
    "        score = 0\n",
    "        # env 초기화\n",
    "        state = env.reset()\n",
    "        state = np.reshape(state, [1, state_size])\n",
    "\n",
    "        while True:\n",
    "            if agent.render:\n",
    "                env.render()\n",
    "            \n",
    "            # 1. Q-Learning과 마찬가지로 step단위로 탐험을 수행함 -> sampling\n",
    "            # 2. 학습을 step단위로 수행함\n",
    "            \n",
    "            # 현재 상태로 행동을 선택\n",
    "            action = agent.get_action(state)\n",
    "            # 선택한 행동으로 환경에서 한 타임스텝 진행\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            next_state = np.reshape(next_state, [1, state_size])\n",
    "            # 에피소드가 중간에 끝나면 -100 보상\n",
    "            reward = reward if not done or score == 499 else -100\n",
    "\n",
    "            # 리플레이 메모리에 샘플 <s, a, r, s'> 저장\n",
    "            agent.append_sample(state, action, reward, next_state, done)\n",
    "            # 매 타임스텝마다 학습\n",
    "            if len(agent.memory) >= agent.train_start:\n",
    "                agent.train_model()\n",
    "\n",
    "            score += reward\n",
    "            state = next_state\n",
    "            global_steps += 1\n",
    "\n",
    "            if done:\n",
    "                # 각 에피소드마다 타깃 모델을 모델의 가중치로 업데이트\n",
    "                agent.update_target_model()\n",
    "\n",
    "                score = score if score == 500 else score + 100\n",
    "                # 에피소드마다 학습 결과 출력\n",
    "                scores.append(score)\n",
    "                episodes.append(e)\n",
    "                plt.plot(episodes, scores)\n",
    "                plt.savefig(\"./save_graph/cartpole_dqn.png\")\n",
    "                print(\"episode:\", e, \"  score:\", score, \"  memory length:\", len(agent.memory),\n",
    "                      \"  epsilon:\", agent.epsilon, \"global steps: \", global_steps)\n",
    "\n",
    "                # 이전 10개 에피소드의 점수 평균이 490보다 크면 학습 중단\n",
    "\n",
    "                if np.mean(scores[-min(10, len(scores)):]) > 490:\n",
    "                    agent.model.save_weights(\"./save_model/cartpole_dqn.h5\")\n",
    "                    agent.render = True\n",
    "                else:\n",
    "                    agent.render = False\n",
    "                break\n",
    "    env.close()\n",
    "    end = datetime.datetime.now()\n",
    "    elapsed = end - start\n",
    "    print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (RL)",
   "language": "python",
   "name": "reinforcement_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
